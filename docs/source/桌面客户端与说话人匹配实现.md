# 桌面客户端与说话人匹配实现（Mac / Electron）（v4.1）

**更新日期**：2026-02-11  
**目标**：在老师的 Mac 上采集 Teams 会议音频，实时上传云端并完成：
- diarization（说话人分段）
- ASR（Fun-ASR realtime 转写）
- enrollment（声纹注册，SV 模型：`iic/speech_campplus_sv_zh_en_16k-common_advanced`）→ speaker 映射到真实姓名
- 会议过程中不强制展示字幕，但必须实时处理，保证“结束即反馈”

---

## 1. 音频采集（Mac）

### 1.1 采集目标
你需要至少两路信息：
- 远端（学生）声音
- 本地（老师）麦克风声音  
并最终合成单路 mono 16k PCM 送入云端 diarization + ASR。

> 现实上，macOS 获取“系统音频回环”有门槛；因此本文给出两条实现路径（建议都做，保证可用性）。

---

## 2. 路径 A（推荐）：ScreenCaptureKit 采集系统/应用音频

### 2.1 适用条件
- macOS 13+（Ventura）
- 用户愿意授权“屏幕录制”（用于捕获窗口/显示器音频）

### 2.2 实现步骤（MVP）
1. Electron 主进程通过 `swift helper` 或 `node-addon` 调用 ScreenCaptureKit
2. 选择采集对象：
   - 最简单：采集整块显示器（包含 Teams 输出音频）
   - 更精细：采集 Teams 应用窗口（若可行）
3. 将回调的 PCM 音频帧送入本地 ring buffer
4. 统一重采样到 **16kHz / mono / PCM16**（SV/ASR/diarization 全链路唯一合法格式）
5. 每 1 秒打包一个 chunk，通过 WebSocket 上传云端

### 2.3 校验方法（必须做成 UI 自检页）
- UI 显示：
  - 输入电平条（远端/本地）
  - 录音状态
  - 1 分钟测试录音回放按钮
- 验收：
  - 远端说话时电平变化明显
  - 本地说话时也有电平变化
  - 回放能听到双向声音

---

## 3. 路径 B（备用）：虚拟声卡（BlackHole/Loopback）

### 3.1 适用条件
- 用户愿意安装音频驱动/工具（更像音频工程方案）
- 对屏幕录制权限敏感或 ScreenCaptureKit 不稳定

### 3.2 推荐配置（BlackHole 2ch）
1. 安装 BlackHole（2ch）
2. Audio MIDI Setup：
   - 创建 Multi-Output Device（Teams 输出 → Mac 扬声器 + BlackHole）
   - 将 Teams 的输出设备设为 Multi-Output Device
3. Electron 通过 Web Audio / native 模块读取 BlackHole 作为输入

### 3.3 校验
- 远端说话时输入电平变化
- 本地说话：仍需从麦克风采集（可与 BlackHole 混合）

---

## 4. 音频上传协议（Electron → Cloudflare）

### 4.1 WebSocket 连接
- URL：`wss://<your-domain>/ws/meeting/<meeting_id>`
- 首包（JSON）：
```json
{
  "type": "hello",
  "meeting_id": "uuid",
  "sample_rate": 16000,
  "format": "pcm_s16le",
  "channels": 1,
  "client_clock_ms": 0
}
```

### 4.2 音频 chunk 包（binary）
- 每包 1 秒：32000 bytes（16k * 2 bytes）
- 辅助 metadata：
```json
{
  "type": "audio_meta",
  "seq": 123,
  "start_ms": 120000,
  "duration_ms": 1000
}
```

✅ **校验**：
- 服务器收到的 seq 连续（允许少量丢包并重传）
- R2 中能看到连续的音频分片对象（按 meeting_id/seq 命名）

---

## 5. 云端实时说话人处理（对接推理服务）

### 5.1 sliding window 策略（推荐默认）
- window = 10s
- hop = 2s
- DO 每 2s 触发一次：
  1. 拉取最近 10 个 chunk（R2）
  2. 调用推理服务 `/diarize`
  3. 获得 segments（示例：每段含 speaker、start_ms、end_ms、score）
  4. 与历史 segments 做去重/合并
  5. 将“稳定段”裁剪音频，送 Fun-ASR realtime

### 5.2 去重/合并规则（MVP 简化）
- 对相同 speaker 的相邻段：
  - gap < 300ms → 合并
- 对滑窗重复：
  - 如果新段与已有段 overlap > 70% → 丢弃新段
- “稳定段”定义：
  - end_ms < now_ms - 1500ms（留出缓冲，避免段落还在增长）

✅ **校验**：
- 在 3 分钟测试中，utterance 不应出现大量重复句子
- utterance 的时间戳单调递增

---

## 6. enrollment（声纹注册）与 speaker 映射

### 6.1 enrollment UI/流程（强制）
- 会中开始：
  - UI 显示参会者列表（来自 Teams/手动）
  - 按顺序提示：请某某自我介绍 5–8 秒
- 系统在该时间窗口内：
  - 捕获音频
  - 调用推理服务 `/enroll`：
    - 输入：音频片段 + displayName/email
    - 输出：embedding + enroll_id

✅ **校验**：
- 每个参与者都拿到 enroll_id
- enroll 音频时长 ≥ 4 秒（阈值可调）

### 6.2 diarization speaker 与 enrolled 的匹配
推理服务提供 `/identify`：
- 输入：一段 speaker_k 的音频（或 embedding）
- 输出：最相似 enrolled（top1 + score）

映射策略（MVP）：
- score ≥ 0.75：自动绑定
- 0.65–0.75：标记“待确认”，在 UI 提示老师一键确认
- < 0.65：unknown，等待更多数据或手动绑定

✅ **校验**：
- 4–6 人会议，完成 enrollment 后 2 分钟内全部 speaker 绑定成功（或仅 1 人需要手动确认）

---

## 7. 会议中不显示字幕时，界面应该呈现什么？

### 7.1 主界面（面试阶段）
- 计时与题目推进
- 参与度仪表盘（实时）：谁说得少/多
- 笔记区：
  - 支持快捷键
  - 记录自动带时间戳
- 一键标记（生成“证据点”）：
  - 👍亮点
  - ⚠️问题
  - ❓追问
  - 🎯证据（会在反馈里引用对应 utterance）

### 7.2 反馈界面（中文）
- 个人反馈卡（每人 5–8 条要点 + 证据原话）
- 团队复盘卡（协作、推进、冲突、共识）
- 可点击证据跳转到对应时间点（播放/回听可选）

---

## 8. 本地/端到端测试清单（你执行时不会出错的版本）

### 8.1 本地音频自检（Day 1 必须过）
- [ ] 能捕获远端声音
- [ ] 能捕获本地声音
- [ ] 录 30 秒回放正常
- [ ] chunk 上传不断流（R2 有连续对象）

### 8.2 云端流水线自检（Day 2 必须过）
- [ ] `/diarize` 返回合理 segments（至少 2 个 speaker）
- [ ] Fun-ASR 返回中间/最终文本
- [ ] utterances 入库，时间戳单调

### 8.3 enrollment+绑定（Day 3 必须过）
- [ ] 4 人 enrollment 成功
- [ ] speaker 自动绑定 ≥ 3 人
- [ ] 手动修正 ≤ 1 人
