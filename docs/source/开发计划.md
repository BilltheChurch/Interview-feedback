# 开发计划（MVP 优先）｜v4.1

**更新日期**：2026-02-11  
**交付目标**：实现“会议中实时处理音频 + enrollment + 说话人绑定 + 面试结束立即反馈”的可用 MVP（Mac + Cloudflare + GPU 推理）

---

## 0. 里程碑总览

| 阶段 | 名称 | 交付物 | 通过标准 |
|---|---|---|---|
| Phase 0 | 账号/环境 | Cloudflare / 阿里云 / GPU 平台可用 | 能跑通最小 demo |
| Phase 1 | 音频采集与上传 | Mac 端可采集 Teams 音频并上传 R2 | 连续 5 分钟不断流 |
| Phase 2 | ASR 实时转写 | Fun-ASR realtime 全链路 | text 入库，P95 < 5s |
| Phase 3 | 说话人日志 + enrollment | diarization + SV + 映射 UI | 4–6 人绑定成功 |
| Phase 4 | 反馈模式 | 个人+团队反馈卡（中文） | 面试结束“秒开” |
| Phase 5（可选） | 质量/成本优化 | 更低延迟/更低成本 | P95 < 3s / 费用可控 |

---

## Phase 0：账号与环境（0.5–1 天）

### 0.1 Cloudflare
**操作**
1. 开通 Cloudflare Workers、R2、Durable Objects、（可选）D1
2. 安装 `wrangler`，创建项目
3. 配置 secrets：
   - `ALIYUN_DASHSCOPE_API_KEY`
   - `INFERENCE_BASE_URL`
   - `INFERENCE_API_KEY`（自定义）

**验证**
- `wrangler dev` 能启动
- `GET /health` 返回 200

### 0.2 阿里云百炼
**操作**
1. 开通 Model Studio / DashScope
2. 获取 Fun-ASR realtime 的 API Key
3. 用官方示例跑通一次 WebSocket（本地脚本）

**验证**
- 本地脚本对一段 wav 返回识别文本

### 0.3 GPU/推理托管平台（部署 diarization/SV）
**操作**
1. 选择平台（见《技术选型与FAQ》）
2. 用 Docker 跑起推理服务（本地→云端）
3. 固定 SV 模型（已定稿）：`iic/speech_campplus_sv_zh_en_16k-common_advanced`
4. 暴露 3 个 HTTP API：
   - `POST /diarize`
   - `POST /enroll`
   - `POST /identify`（基于 embedding 的 top1 匹配 + 阈值决策）

**验证**
- `curl` 调用 3 个接口均返回 200
- `identify` 对同一人两段音频相似度明显更高

---

## Phase 1：Mac 音频采集 → 上传 R2（2–4 天）

### MVP 任务列表
- [ ] Electron 框架（窗口、任务列表、会议页面）
- [ ] 音频采集（先实现一种路径；建议 ScreenCaptureKit）
- [ ] PCM 统一：16kHz / mono / s16le
- [ ] WebSocket 上传（1s chunks）
- [ ] R2 落盘（按 meeting_id/seq）
- [ ] 自检 UI（电平条 + 回放）

### 操作步骤（你按这套做不会走弯路）
1. 先做本地录音文件输出（不要急着上云）
2. 能录到 Teams 远端与本地后，再接 WebSocket
3. WebSocket 通了再接 R2 落盘
4. 最后做回放（从 R2 拉回合成）

### 验证标准
- 连续 5 分钟上传无断流
- R2 中 seq 连续（允许极少丢包）
- 从 R2 合成 wav 回放清晰

---

## Phase 2：ASR（Fun-ASR realtime）全链路（2–3 天）

### MVP 任务列表
- [ ] Worker/DO 调用 Fun-ASR realtime
- [ ] 将音频段送入 Fun-ASR（先不做 diarization，先整段转写验证）
- [ ] 结果入库（utterances_raw）
- [ ] 错误重试与熔断（网络/限流）

### 操作流程（一步一步 + 检验）
1. 在 DO 中实现“拉最近 N 秒音频 → 合成 10s wav → 送 ASR”
2. 先用固定 10s 窗口每 10s 识别一次（牺牲实时性换确定性）
3. 成功后再把周期改到 2–3s（提高实时性）

**检验**
- 每 10s 有一条识别结果
- 识别文本大体正确（可接受错词）
- 端到端延迟 P95 < 8s（先宽松）

---

## Phase 3：Diarization + enrollment + speaker 绑定（4–7 天）

### MVP 任务列表
- [ ] 推理服务：diarization pipeline（滑窗 10s/hop 2s）
- [ ] 推理服务：SV embedding + enroll/identify
- [ ] DO：segment 去重/合并
- [ ] DO：稳定段裁剪 → Fun-ASR → utterances（带 speaker）
- [ ] Electron：enrollment 引导 UI + 映射确认 UI
- [ ] 手动修正映射（兜底）

### 操作流程（一步一步 + 检验）
1. 先在本地用录音跑 diarization：确认能分出 2–3 个 speaker
2. 再接到云端推理服务
3. 打通 enrollment：每人说 5–8 秒 → enroll 成功
4. 打通 identify：speaker_k → 名字（score 阈值）
5. 最后把 speaker_name 写入 utterances

**检验**
- 4 人测试会议：
  - enrollment 全部成功
  - speaker 自动绑定 ≥ 3 人
  - 绑定后 utterances 中 speaker_name 稳定

---

## Phase 4：反馈模式（3–5 天）

### MVP 任务列表
- [ ] 反馈触发按钮（面试结束）
- [ ] LLM 生成个人/团队反馈（中文）
- [ ] 证据引用：引用对应 utterance + 时间戳
- [ ] UI：反馈卡片展示（可复制/导出）

### 操作流程（一步一步 + 检验）
1. 先用固定模板规则生成“参与度 + 关键词统计”的简版反馈（不依赖 LLM）
2. 再接 LLM（千问等），生成可读反馈
3. 做“秒开”：会议过程中持续更新草稿，点击后只做增量刷新

**检验**
- 点击进入反馈首屏 < 1s
- 反馈内容能引用到具体 utterance（至少每人 3 条证据）

---

## Phase 5：优化（可选）
- 降低延迟：更小 hop、更快稳定段判定
- 降低成本：GPU 服务按需启动；闲置自动缩容
- 质量提升：VAD、重叠处理、ASR 热词

